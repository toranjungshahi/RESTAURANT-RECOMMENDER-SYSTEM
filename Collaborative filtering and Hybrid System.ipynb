{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a65cf228",
   "metadata": {
    "id": "a65cf228"
   },
   "source": [
    "## Collaborative filtering recommender system\n",
    "\n",
    "- Dataset: first 10000 restaurant reviews in Philadelphia\n",
    "    - Total reviews : 10000\n",
    "    - Total users: 8236\n",
    "    - Total restaurants: 470\n",
    "- Models:\n",
    "    - Singular Value Decomposition model (SVD)\n",
    "    - Neural Collaborative Filtering model (NCF)\n",
    "- Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cd65003",
   "metadata": {
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1700785001366,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "2cd65003"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ee0cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19058,
     "status": "ok",
     "timestamp": 1700785020419,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "zK1HCdGXW2L1",
    "outputId": "c1dbe45b-f17b-40e2-d527-d0ed9a709df4"
   },
   "source": [
    "#Mount google drive,uncomment below if running in collab, change path accordingly\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "yJG3nbrxAARi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79125,
     "status": "ok",
     "timestamp": 1700785099537,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "yJG3nbrxAARi",
    "outputId": "8c536a09-6b81-4ee7-85e8-82df32205dea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Using cached surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
      "Collecting scikit-surprise\n",
      "  Using cached scikit-surprise-1.1.3.tar.gz (771 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\toran\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\toran\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\toran\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.10.1)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py): started\n",
      "  Building wheel for scikit-surprise (setup.py): finished with status 'done'\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-win_amd64.whl size=1085601 sha256=a17fa4916c047e1be8f2067dbfa2822986a77f05555197193caed72b00b99402\n",
      "  Stored in directory: c:\\users\\toran\\appdata\\local\\pip\\cache\\wheels\\df\\e4\\a6\\7ad72453dd693f420b0c639bedeec34641738d11b55d8d9b84\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "Successfully installed scikit-surprise-1.1.3 surprise-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "uCneIUebmq_1",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1700785099537,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "uCneIUebmq_1"
   },
   "outputs": [],
   "source": [
    "path_to_review = 'review_philadelphia_50000.json'\n",
    "path_to_business = 'business_philadelphia.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb18352",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2051,
     "status": "ok",
     "timestamp": 1700785101582,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "9fb18352",
    "outputId": "824bd8f3-a614-426c-d327-efe01b958c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 10000 reviews: (10000, 3)\n",
      "Attributes in the review dataframe: Index(['user_id', 'business_id', 'stars'], dtype='object')\n",
      "Shape of all restaurants in Philadelphia: (5853, 10)\n",
      "Attributes in the restaurant dataframe: Index(['business_id', 'name', 'address', 'latitude', 'longitude', 'stars',\n",
      "       'review_count', 'attributes', 'categories', 'hours'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read review data from json file\n",
    "review_philadelphia_original_df = pd.read_json(path_to_review, lines=True)\n",
    "\n",
    "review_philadelphia_df = review_philadelphia_original_df[:10000]\n",
    "\n",
    "review_philadelphia_df = review_philadelphia_df[['user_id', 'business_id', 'stars']]\n",
    "print('Shape of 10000 reviews:', review_philadelphia_df.shape)\n",
    "print('Attributes in the review dataframe:', review_philadelphia_df.columns)\n",
    "\n",
    "# read business data\n",
    "restaurant_philadelphia_df = pd.read_json(path_to_business, lines=True)\n",
    "restaurant_philadelphia_df = restaurant_philadelphia_df.drop(['city', 'state', 'postal_code', 'is_open'], axis=1)\n",
    "\n",
    "print('Shape of all restaurants in Philadelphia:', restaurant_philadelphia_df.shape)\n",
    "print('Attributes in the restaurant dataframe:', restaurant_philadelphia_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139cd224",
   "metadata": {
    "id": "139cd224"
   },
   "source": [
    "### Data preprocessing\n",
    "- Find all the `user_id` in the dataset to the array `users`\n",
    "- Find all the `business_id` in the dataset to the array `restaurants`\n",
    "- Convert all the `user_id` to its index in `users`\n",
    "- Convert all the `business_id` to its index in `restaurant`\n",
    "- Remove the duplicate review in review dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3bffbe0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1700785101582,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "c3bffbe0",
    "outputId": "55e2259e-c25a-4625-f1df-2fc8e2f6cf2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user 8236\n",
      "Number of restaurant 470\n"
     ]
    }
   ],
   "source": [
    "# find all the restaurant_id and user_id in review dataframe\n",
    "users = review_philadelphia_df['user_id'].unique()\n",
    "restaurants = review_philadelphia_df['business_id'].unique()\n",
    "\n",
    "print('Number of user', users.shape[0])\n",
    "print('Number of restaurant', restaurants.shape[0])\n",
    "\n",
    "# Remove duplicate review by unique ['user_id', 'business_id']\n",
    "review_df_no_duplicates = review_philadelphia_df[~review_philadelphia_df.duplicated(subset=['user_id', 'business_id'])]\n",
    "\n",
    "# Resetting the indices of the dataframe to make them contiguous\n",
    "review_df_no_duplicates = review_df_no_duplicates.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df5cbrvr2vpx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1700785101582,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "df5cbrvr2vpx",
    "outputId": "47d60330-d6cf-41d8-831f-70b28b6fe980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                  user_id             business_id  stars\n",
       " 0  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA      5\n",
       " 1  eUta8W_HdHMXPzLBBZhL1A  04UD14gamNjLY0IDYVhHJg      1\n",
       " 2  smOvOajNG0lS4Pq7d8g4JQ  RZtGWDLCAtuipwaZ-UfjmQ      4\n",
       " 3  Dd1jQj7S-BFGqRbApFzCFw  YtSqYv1Q_pOltsVPSx54SA      5\n",
       " 4  IQsF3Rc6IgCzjVV9DE8KXg  eFvzHawVJofxSnD7TgbZtg      5,\n",
       " (10000, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_philadelphia_df.head(),review_philadelphia_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb92000e",
   "metadata": {
    "id": "fb92000e"
   },
   "source": [
    "### Cross-validation of SVD model\n",
    "- Dataset: all 10000 reviews\n",
    "- Folds: 5\n",
    "- Loss function: MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d0424b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9699,
     "status": "ok",
     "timestamp": 1700785111277,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "1d0424b0",
    "outputId": "ddd07357-4142-4ddb-9e20-4552346a2582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "MSE (testset)     1.4226  1.4151  1.4377  1.4096  1.4040  1.4178  0.0117  \n",
      "MAE (testset)     0.9509  0.9472  0.9497  0.9497  0.9342  0.9463  0.0062  \n",
      "Fit time          0.54    0.44    0.52    0.43    0.44    0.47    0.05    \n",
      "Test time         0.02    0.02    0.01    0.02    0.02    0.02    0.00    \n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD, accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "review_df_no_duplicates_svd = review_df_no_duplicates.copy()\n",
    "review_df_no_duplicates_svd.columns = [\"user_id\", \"business_id\", \"stars\"]\n",
    "\n",
    "# converting dataframe to desired format by surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(review_df_no_duplicates_svd[[\"user_id\",\n",
    "                                                     \"business_id\",\n",
    "                                                     \"stars\"]], reader)\n",
    "\n",
    "# Use the SVD algorithm\n",
    "svd_model = SVD(n_factors=100, n_epochs=100, biased=True)\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_validate(svd_model, data, measures=['MSE', 'MAE'], cv=5, verbose=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f815862",
   "metadata": {
    "executionInfo": {
     "elapsed": 2081,
     "status": "ok",
     "timestamp": 1700785113331,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "9f815862"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(review_df_no_duplicates, test_size=0.25, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c1f1a1",
   "metadata": {
    "id": "f6c1f1a1"
   },
   "source": [
    "### Training SVD model\n",
    "- Dataset: all 10000 reviews, 75% for training set, 25% for test set\n",
    "- Number of Embeddings: 100\n",
    "- Epochs: 100\n",
    "- Optimizer: Stochastic Gradient Descent\n",
    "- Learning rate: 0.05\n",
    "- Loss function: MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edcd2262",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2704,
     "status": "ok",
     "timestamp": 1700785116031,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "edcd2262",
    "outputId": "a0e67827-2624-45d3-b1a0-4b41a02d09d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x20d0152bf70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dividing the data as trainset and testset\n",
    "train_df_svd = train_df.copy()\n",
    "# train_df_svd.columns = [\"user_id\", \"business_id\", \"stars\"]\n",
    "train_data = Dataset.load_from_df(train_df_svd[['user_id', 'business_id', 'stars']], reader)\n",
    "trainset = train_data.build_full_trainset()\n",
    "\n",
    "test_df_svd = test_df.copy()\n",
    "# test_df_svd.columns = [\"user_id\", \"business_id\", \"stars\"]\n",
    "test_data = Dataset.load_from_df(test_df_svd[['user_id', 'business_id', 'stars']], reader)\n",
    "testset = test_data.build_full_trainset().build_testset()\n",
    "\n",
    "# building model on train set\n",
    "svd_model.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8117ed",
   "metadata": {
    "id": "2c8117ed"
   },
   "source": [
    "### Evaluation of SVD model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "916d73c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1700785116031,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "916d73c3",
    "outputId": "40ee000f-0632-474c-fe1a-42b75189c70b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "MSE and MAE of the SVD prediction:\n",
      "\n",
      "MSE: 1.3852\n",
      "MAE:  0.9382\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------------------------------------------------------------------------------')\n",
    "\n",
    "# testing model on test set\n",
    "prediction = svd_model.test(testset)\n",
    "print('MSE and MAE of the SVD prediction:')\n",
    "print()\n",
    "accuracy.mse(prediction)\n",
    "accuracy.mae(prediction)\n",
    "\n",
    "print('----------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931e14f",
   "metadata": {
    "id": "f931e14f"
   },
   "source": [
    "### Build NCF model\n",
    "Reference: X. He, L. Liao, H. Zhang, L. Nie, X. Hu and T.-S. Chua. Neural Collaborative Filtering. 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5b5a79a",
   "metadata": {
    "executionInfo": {
     "elapsed": 6080,
     "status": "ok",
     "timestamp": 1700785122089,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "c5b5a79a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Flatten, Input, Dropout, Dense, Concatenate, Dot\n",
    "from keras.optimizers import Adam\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Define the NCF model\n",
    "def get_model(num_users, num_items, latent_dim):\n",
    "    # Define inputs\n",
    "    item_input = Input(shape=[1], name='item-input')\n",
    "    user_input = Input(shape=[1], name='user-input')\n",
    "\n",
    "    # MLP Embeddings\n",
    "    item_embedding_mlp = Embedding(num_items + 1, latent_dim, name='item-embedding-mlp')(item_input)\n",
    "    item_vec_mlp = Flatten(name='flatten-item-mlp')(item_embedding_mlp)\n",
    "\n",
    "    user_embedding_mlp = Embedding(num_users + 1, latent_dim, name='user-embedding-mlp')(user_input)\n",
    "    user_vec_mlp = Flatten(name='flatten-user-mlp')(user_embedding_mlp)\n",
    "\n",
    "    # MF Embeddings\n",
    "    item_embedding_mf = Embedding(num_items + 1, latent_dim, name='item-embedding-mf')(item_input)\n",
    "    item_vec_mf = Flatten(name='flatten-item-mf')(item_embedding_mf)\n",
    "\n",
    "    user_embedding_mf = Embedding(num_users + 1, latent_dim, name='user-embedding-mf')(user_input)\n",
    "    user_vec_mf = Flatten(name='flatten-user-mf')(user_embedding_mf)\n",
    "\n",
    "    # MLP layers\n",
    "    concat = Concatenate(name='concat')([item_vec_mlp, user_vec_mlp])\n",
    "    concat_dropout = Dropout(0.2)(concat)\n",
    "    fc_1 = Dense(100, name='fc-1', activation='relu')(concat_dropout)\n",
    "    fc_1_dropout = Dropout(0.2)(fc_1)\n",
    "    fc_2 = Dense(50, name='fc-2', activation='relu')(fc_1_dropout)\n",
    "    fc_2_dropout = Dropout(0.2)(fc_2)\n",
    "\n",
    "    # Prediction from both layers\n",
    "    pred_mlp = Dense(10, name='pred-mlp', activation='relu')(fc_2_dropout)\n",
    "    pred_mf = Dot(axes=-1, normalize=False)([item_vec_mf, user_vec_mf])\n",
    "    combine_mlp_mf = Concatenate(name='combine-mlp-mf')([pred_mf, pred_mlp])\n",
    "\n",
    "    # Final prediction\n",
    "    result = Dense(1, name='result', activation='relu')(combine_mlp_mf)\n",
    "\n",
    "    model = Model([user_input, item_input], result)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c67c90b8",
   "metadata": {
    "executionInfo": {
     "elapsed": 19682,
     "status": "ok",
     "timestamp": 1700785141744,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "c67c90b8"
   },
   "outputs": [],
   "source": [
    "# convert all the user_id and business_id in review dataframe to their index in user_ids and restaurant_ids\n",
    "def replace_ids(row):\n",
    "    # Get the 'title_id' and 'business_id' values from the row\n",
    "    user_id = row['user_id']\n",
    "    business_id = row['business_id']\n",
    "\n",
    "    user_index = np.argmax(users == user_id)\n",
    "    business_index = np.argmax(restaurants == business_id)\n",
    "\n",
    "    return pd.Series([user_index, business_index], index=['user_id', 'business_id'])\n",
    "\n",
    "# get review data for ncf\n",
    "review_df_no_duplicates_ncf = review_df_no_duplicates.copy()\n",
    "\n",
    "# Apply the function to change 'title_id' and 'movie_id' values in the DataFrame\n",
    "review_df_no_duplicates_ncf[['user_id', 'business_id']] = review_df_no_duplicates_ncf.apply(replace_ids, axis=1)\n",
    "\n",
    "# change the column name of the dataframe\n",
    "review_df_no_duplicates_ncf.columns = [\"user\", \"item\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aClOmsjDt5L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1700785141744,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "5aClOmsjDt5L",
    "outputId": "039f940c-48ab-44ce-9773-c9d9ec6b0df1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9925, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_no_duplicates_ncf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22289b2e",
   "metadata": {
    "id": "22289b2e"
   },
   "source": [
    "### Cross-validation of NCF model\n",
    "- Dataset: all 10000 reviews\n",
    "- Folds: 5\n",
    "- Loss function: MAE, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "NhqXMOr6E-nJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1700785141744,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "NhqXMOr6E-nJ",
    "outputId": "ba960f9f-41de-48a7-95f0-e399fbff2c73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  label\n",
       "0     0     0      5\n",
       "1     1     1      1\n",
       "2     2     2      4\n",
       "3     3     3      5\n",
       "4     4     4      5\n",
       "5     5     5      5\n",
       "6     6     6      4\n",
       "7     7     7      5\n",
       "8     8     8      4\n",
       "9     9     9      5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_no_duplicates_ncf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "235e1582",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 606682,
     "status": "ok",
     "timestamp": 1700785748421,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "235e1582",
    "outputId": "b569264b-069b-49d0-d405-85a3df9efe70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [   0    1    4 ... 9921 9922 9923], Validation indices: [   2    3    8 ... 9911 9913 9918]\n",
      "Epoch 1/20\n",
      "249/249 [==============================] - 6s 18ms/step - loss: 1.1684 - mean_squared_error: 2.2317 - mae: 1.1684\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.8150 - mean_squared_error: 1.0751 - mae: 0.8150\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.6260 - mean_squared_error: 0.6518 - mae: 0.6260\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.5009 - mean_squared_error: 0.3995 - mae: 0.5009\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.3984 - mean_squared_error: 0.2609 - mae: 0.3984\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.3504 - mean_squared_error: 0.2058 - mae: 0.3504\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.3426 - mean_squared_error: 0.1914 - mae: 0.3426\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.3217 - mean_squared_error: 0.1743 - mae: 0.3217\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 5s 19ms/step - loss: 0.3122 - mean_squared_error: 0.1616 - mae: 0.3122\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2911 - mean_squared_error: 0.1401 - mae: 0.2911\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2870 - mean_squared_error: 0.1365 - mae: 0.2870\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2730 - mean_squared_error: 0.1223 - mae: 0.2730\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2664 - mean_squared_error: 0.1186 - mae: 0.2664\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2578 - mean_squared_error: 0.1108 - mae: 0.2578\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2502 - mean_squared_error: 0.1058 - mae: 0.2502\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2375 - mean_squared_error: 0.0939 - mae: 0.2375\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2371 - mean_squared_error: 0.0928 - mae: 0.2371\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2300 - mean_squared_error: 0.0881 - mae: 0.2300\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2278 - mean_squared_error: 0.0862 - mae: 0.2278\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2157 - mean_squared_error: 0.0778 - mae: 0.2157\n",
      "63/63 - 0s - loss: 0.9786 - mean_squared_error: 1.5458 - mae: 0.9786 - 301ms/epoch - 5ms/step\n",
      "Train indices: [   0    1    2 ... 9919 9921 9922], Validation indices: [   6   18   33 ... 9915 9920 9923]\n",
      "Epoch 1/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 1.2383 - mean_squared_error: 2.5510 - mae: 1.2383\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.8515 - mean_squared_error: 1.1479 - mae: 0.8515\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.6699 - mean_squared_error: 0.7318 - mae: 0.6699\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.5236 - mean_squared_error: 0.4425 - mae: 0.5236\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.4201 - mean_squared_error: 0.2870 - mae: 0.4201\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.3554 - mean_squared_error: 0.2101 - mae: 0.3554\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.3342 - mean_squared_error: 0.1830 - mae: 0.3342\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2980 - mean_squared_error: 0.1527 - mae: 0.2980\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2855 - mean_squared_error: 0.1379 - mae: 0.2855\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 5s 19ms/step - loss: 0.2634 - mean_squared_error: 0.1203 - mae: 0.2634\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 5s 19ms/step - loss: 0.2540 - mean_squared_error: 0.1131 - mae: 0.2540\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2436 - mean_squared_error: 0.1031 - mae: 0.2436\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2395 - mean_squared_error: 0.1015 - mae: 0.2395\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 5s 19ms/step - loss: 0.2533 - mean_squared_error: 0.1180 - mae: 0.2533\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2456 - mean_squared_error: 0.1057 - mae: 0.2456\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2303 - mean_squared_error: 0.0957 - mae: 0.2303\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2187 - mean_squared_error: 0.0847 - mae: 0.2187\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2050 - mean_squared_error: 0.0748 - mae: 0.2050\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.1986 - mean_squared_error: 0.0676 - mae: 0.1986\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.1875 - mean_squared_error: 0.0615 - mae: 0.1875\n",
      "63/63 - 0s - loss: 0.9513 - mean_squared_error: 1.5327 - mae: 0.9513 - 251ms/epoch - 4ms/step\n",
      "Train indices: [   1    2    3 ... 9918 9920 9923], Validation indices: [   0    4   19 ... 9919 9921 9922]\n",
      "Epoch 1/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 1.1629 - mean_squared_error: 2.2414 - mae: 1.1629\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.7670 - mean_squared_error: 0.9766 - mae: 0.7670\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.5749 - mean_squared_error: 0.5800 - mae: 0.5749\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.4916 - mean_squared_error: 0.3948 - mae: 0.4916\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.4096 - mean_squared_error: 0.2806 - mae: 0.4096\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.3682 - mean_squared_error: 0.2215 - mae: 0.3682\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.3427 - mean_squared_error: 0.1885 - mae: 0.3427\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 5s 19ms/step - loss: 0.3065 - mean_squared_error: 0.1557 - mae: 0.3065\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.3020 - mean_squared_error: 0.1479 - mae: 0.3020\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2664 - mean_squared_error: 0.1160 - mae: 0.2664\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2620 - mean_squared_error: 0.1122 - mae: 0.2620\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2513 - mean_squared_error: 0.1041 - mae: 0.2513\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2402 - mean_squared_error: 0.0948 - mae: 0.2402\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2377 - mean_squared_error: 0.0907 - mae: 0.2377\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2259 - mean_squared_error: 0.0844 - mae: 0.2259\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2217 - mean_squared_error: 0.0800 - mae: 0.2217\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2139 - mean_squared_error: 0.0755 - mae: 0.2139\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 5s 19ms/step - loss: 0.2063 - mean_squared_error: 0.0713 - mae: 0.2063\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2038 - mean_squared_error: 0.0689 - mae: 0.2038\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2028 - mean_squared_error: 0.0682 - mae: 0.2028\n",
      "63/63 - 0s - loss: 0.9917 - mean_squared_error: 1.5733 - mae: 0.9917 - 249ms/epoch - 4ms/step\n",
      "Train indices: [   0    2    3 ... 9921 9922 9923], Validation indices: [   1    5    7 ... 9910 9912 9917]\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 5s 18ms/step - loss: 1.1835 - mean_squared_error: 2.3180 - mae: 1.1835\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.7982 - mean_squared_error: 1.0464 - mae: 0.7982\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 4s 17ms/step - loss: 0.5957 - mean_squared_error: 0.5986 - mae: 0.5957\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 4s 17ms/step - loss: 0.4727 - mean_squared_error: 0.3653 - mae: 0.4727\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.4034 - mean_squared_error: 0.2673 - mae: 0.4034\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.3648 - mean_squared_error: 0.2176 - mae: 0.3648\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 4s 17ms/step - loss: 0.3357 - mean_squared_error: 0.1815 - mae: 0.3357\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.3000 - mean_squared_error: 0.1479 - mae: 0.3000\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2978 - mean_squared_error: 0.1420 - mae: 0.2978\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2737 - mean_squared_error: 0.1227 - mae: 0.2737\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2709 - mean_squared_error: 0.1193 - mae: 0.2709\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2491 - mean_squared_error: 0.1020 - mae: 0.2491\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2451 - mean_squared_error: 0.0988 - mae: 0.2451\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 4s 17ms/step - loss: 0.2385 - mean_squared_error: 0.0940 - mae: 0.2385\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 4s 17ms/step - loss: 0.2382 - mean_squared_error: 0.0934 - mae: 0.2382\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2286 - mean_squared_error: 0.0845 - mae: 0.2286\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2220 - mean_squared_error: 0.0816 - mae: 0.2220\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 4s 17ms/step - loss: 0.2248 - mean_squared_error: 0.0849 - mae: 0.2248\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2119 - mean_squared_error: 0.0739 - mae: 0.2119\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2101 - mean_squared_error: 0.0735 - mae: 0.2101\n",
      "63/63 - 0s - loss: 1.0116 - mean_squared_error: 1.6322 - mae: 1.0116 - 378ms/epoch - 6ms/step\n",
      "Train indices: [   0    1    2 ... 9921 9922 9923], Validation indices: [  10   13   16 ... 9906 9908 9909]\n",
      "Epoch 1/20\n",
      "249/249 [==============================] - 5s 17ms/step - loss: 1.1943 - mean_squared_error: 2.3672 - mae: 1.1943\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.8016 - mean_squared_error: 1.0518 - mae: 0.8016\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.5980 - mean_squared_error: 0.6100 - mae: 0.5980\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.4921 - mean_squared_error: 0.3940 - mae: 0.4921\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.4191 - mean_squared_error: 0.2887 - mae: 0.4191\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.3717 - mean_squared_error: 0.2273 - mae: 0.3717\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.3445 - mean_squared_error: 0.1931 - mae: 0.3445\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.3111 - mean_squared_error: 0.1607 - mae: 0.3111\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2976 - mean_squared_error: 0.1463 - mae: 0.2976\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2856 - mean_squared_error: 0.1374 - mae: 0.2856\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2719 - mean_squared_error: 0.1219 - mae: 0.2719\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 4s 17ms/step - loss: 0.2583 - mean_squared_error: 0.1097 - mae: 0.2583\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2464 - mean_squared_error: 0.0995 - mae: 0.2464\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2332 - mean_squared_error: 0.0885 - mae: 0.2332\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2223 - mean_squared_error: 0.0811 - mae: 0.2223\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2288 - mean_squared_error: 0.0859 - mae: 0.2288\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 5s 18ms/step - loss: 0.2184 - mean_squared_error: 0.0796 - mae: 0.2184\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2149 - mean_squared_error: 0.0757 - mae: 0.2149\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.2084 - mean_squared_error: 0.0724 - mae: 0.2084\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 0.1969 - mean_squared_error: 0.0644 - mae: 0.1969\n",
      "62/62 - 0s - loss: 0.9625 - mean_squared_error: 1.5358 - mae: 0.9625 - 227ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "train_df_kfold, test_df_kfold = train_test_split(review_df_no_duplicates_ncf, test_size=0.00001, random_state=17)\n",
    "#train_df_kfold.reset_index(drop=True,inplace =True)\n",
    "\n",
    "for train_index, val_index in kf.split(train_df_kfold):\n",
    "    print(f\"Train indices: {train_index}, Validation indices: {val_index}\")\n",
    "    train_set = train_df_kfold.iloc[train_index]\n",
    "    val_set = train_df_kfold.iloc[val_index]\n",
    "\n",
    "    ncf_model = get_model(users.shape[0], restaurants.shape[0], 100)\n",
    "    ncf_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_absolute_error', metrics=['mean_squared_error', 'mae'])\n",
    "\n",
    "    ncf_model.fit([train_set.user, train_set.item], train_set.label, epochs=20, verbose='auto')\n",
    "\n",
    "    _, mae, mse = ncf_model.evaluate([val_set.user, val_set.item], val_set.label, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f185990",
   "metadata": {
    "id": "2f185990"
   },
   "source": [
    "### Training NCF model\n",
    "- Dataset: all 10000 reviews, 75% for training set, 25% for test set\n",
    "- Number of Embeddings: 100\n",
    "- Epochs: 20\n",
    "- Optimizer: Stochastic Gradient Descent\n",
    "- Learning rate: 0.01\n",
    "- Loss function: MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce982977",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1700785749075,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "ce982977",
    "outputId": "4814b620-23d2-4fe2-dd2d-7719add6dc73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " item-input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " user-input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " item-embedding-mlp (Embedding)  (None, 1, 100)      47100       ['item-input[0][0]']             \n",
      "                                                                                                  \n",
      " user-embedding-mlp (Embedding)  (None, 1, 100)      823700      ['user-input[0][0]']             \n",
      "                                                                                                  \n",
      " flatten-item-mlp (Flatten)     (None, 100)          0           ['item-embedding-mlp[0][0]']     \n",
      "                                                                                                  \n",
      " flatten-user-mlp (Flatten)     (None, 100)          0           ['user-embedding-mlp[0][0]']     \n",
      "                                                                                                  \n",
      " concat (Concatenate)           (None, 200)          0           ['flatten-item-mlp[0][0]',       \n",
      "                                                                  'flatten-user-mlp[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 200)          0           ['concat[0][0]']                 \n",
      "                                                                                                  \n",
      " fc-1 (Dense)                   (None, 100)          20100       ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 100)          0           ['fc-1[0][0]']                   \n",
      "                                                                                                  \n",
      " item-embedding-mf (Embedding)  (None, 1, 100)       47100       ['item-input[0][0]']             \n",
      "                                                                                                  \n",
      " user-embedding-mf (Embedding)  (None, 1, 100)       823700      ['user-input[0][0]']             \n",
      "                                                                                                  \n",
      " fc-2 (Dense)                   (None, 50)           5050        ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " flatten-item-mf (Flatten)      (None, 100)          0           ['item-embedding-mf[0][0]']      \n",
      "                                                                                                  \n",
      " flatten-user-mf (Flatten)      (None, 100)          0           ['user-embedding-mf[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 50)           0           ['fc-2[0][0]']                   \n",
      "                                                                                                  \n",
      " dot_5 (Dot)                    (None, 1)            0           ['flatten-item-mf[0][0]',        \n",
      "                                                                  'flatten-user-mf[0][0]']        \n",
      "                                                                                                  \n",
      " pred-mlp (Dense)               (None, 10)           510         ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " combine-mlp-mf (Concatenate)   (None, 11)           0           ['dot_5[0][0]',                  \n",
      "                                                                  'pred-mlp[0][0]']               \n",
      "                                                                                                  \n",
      " result (Dense)                 (None, 1)            12          ['combine-mlp-mf[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,767,272\n",
      "Trainable params: 1,767,272\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# show the model structure\n",
    "ncf_model = get_model(users.shape[0], restaurants.shape[0], 100)\n",
    "ncf_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_absolute_error', metrics=['mean_squared_error', 'mae'])\n",
    "ncf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "414fcf97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1285,
     "status": "error",
     "timestamp": 1700785750350,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "414fcf97",
    "outputId": "32e3f3ff-ffaa-43f5-e781-fe85fb1365fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_5/Cast' defined at (most recent call last):\n    File \"C:\\Users\\toran\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\toran\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\toran\\AppData\\Local\\Temp\\ipykernel_23276\\1332832854.py\", line 9, in <module>\n      history = ncf_model.fit([train_df_ncf.user, train_df_ncf.item], train_df_ncf.label, epochs=20)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 651, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 748, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'model_5/Cast'\nCast string to float is not supported\n\t [[{{node model_5/Cast}}]] [Op:__inference_train_function_138494]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m test_df_ncf\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# train NCF model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mncf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_df_ncf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df_ncf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df_ncf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m pd\u001b[38;5;241m.\u001b[39mSeries(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mplot(logy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_5/Cast' defined at (most recent call last):\n    File \"C:\\Users\\toran\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\toran\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\toran\\AppData\\Local\\Temp\\ipykernel_23276\\1332832854.py\", line 9, in <module>\n      history = ncf_model.fit([train_df_ncf.user, train_df_ncf.item], train_df_ncf.label, epochs=20)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 651, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"C:\\Users\\toran\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 748, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'model_5/Cast'\nCast string to float is not supported\n\t [[{{node model_5/Cast}}]] [Op:__inference_train_function_138494]"
     ]
    }
   ],
   "source": [
    "# format the train_df and test_df\n",
    "train_df_ncf = train_df.copy()\n",
    "train_df_ncf.columns = [\"user\", \"item\", \"label\"]\n",
    "test_df_ncf = test_df.copy()\n",
    "test_df_ncf.columns = [\"user\", \"item\", \"label\"]\n",
    "\n",
    "\n",
    "# train NCF model\n",
    "history = ncf_model.fit([train_df_ncf.user, train_df_ncf.item], train_df_ncf.label, epochs=20)\n",
    "pd.Series(history.history['loss']).plot(logy=True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2d365c",
   "metadata": {
    "id": "ef2d365c"
   },
   "source": [
    "### Evaluation of SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8750a4",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1700785750350,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "3c8750a4"
   },
   "outputs": [],
   "source": [
    "# evaluate NCF model\n",
    "ncf_model.evaluate([test_df_ncf.user, test_df_ncf.item],  test_df_ncf.label, verbose=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7abf066",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1700785750350,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "a7abf066"
   },
   "outputs": [],
   "source": [
    "prediction = ncf_model.predict([np.array([0]), np.array([5])])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d719ae",
   "metadata": {
    "id": "40d719ae"
   },
   "source": [
    "### Conclusion of Collaborative filtering recommender system\n",
    "- Cross-validation\n",
    "    - SVD is better\n",
    "- Preidction\n",
    "    - NCF is better\n",
    "- Speed\n",
    "    - SVD is much faster than NCF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77798a6a",
   "metadata": {
    "id": "77798a6a"
   },
   "source": [
    "### Hybrid recommender system\n",
    "- Combine content-based and collaborative filtering system together\n",
    "- The output of content-based system will be the input of collaborative filtering system\n",
    "- Output of the content-based system: Top_10 recommended restaurants\n",
    "- CF system will try to recommend Top_5 restaurants inside the output of content-based system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88daaa2b",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1700785750351,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "88daaa2b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "review_restaurant_sampled_origin = review_philadelphia_original_df\n",
    "review_restaurant_sampled_origin = review_restaurant_sampled_origin[~review_restaurant_sampled_origin.duplicated(subset=['user_id', 'business_id'])]\n",
    "\n",
    "# Resetting the indices of the dataframe to make them contiguous\n",
    "review_restaurant_sampled_origin = review_restaurant_sampled_origin.reset_index(drop=True)\n",
    "\n",
    "# Importing data into Pandas DataFrames\n",
    "business_restaurant = restaurant_philadelphia_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3b3e9",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1700785750351,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "14b3b3e9"
   },
   "outputs": [],
   "source": [
    "review_restaurant_sampled = review_restaurant_sampled_origin.loc[:9999]\n",
    "review_restaurant_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c807e",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1700785750351,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "ad0c807e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Assuming the data has already been loaded into the following Pandas DataFrames\n",
    "# business_restaurant, review_restaurant, business_philadelphia, review_philadelphia\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "import re\n",
    "\n",
    "# Function to clean text data\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Optionally, more preprocessing steps like stopword removal, stemming, etc.\n",
    "    return text\n",
    "\n",
    "# Apply the text cleaning function to review data\n",
    "review_restaurant_sampled['text'] = review_restaurant_sampled['text'].apply(clean_text)\n",
    "\n",
    "\n",
    "# Step 2: Feature Engineering\n",
    "# Use TF-IDF to transform text data into feature vectors.\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Combine all reviews for each business\n",
    "business_reviews = review_restaurant_sampled.groupby('business_id')['text'].apply(lambda reviews: ' '.join(reviews))\n",
    "business_reviews = business_reviews.reset_index()\n",
    "\n",
    "# Compute TF-IDF matrix for the review text\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(business_reviews['text'])\n",
    "\n",
    "# Create a mapping from the original DataFrame index to the row numbers in the TF-IDF matrix\n",
    "index_to_row_mapping = {index: row_number for row_number, index in enumerate(business_reviews['business_id'].values)}\n",
    "\n",
    "# Function to average TF-IDF vectors by user\n",
    "def average_tfidf_vectors(reviews):\n",
    "    # Map the original indices to the corresponding rows in the TF-IDF matrix\n",
    "    rows_to_use = [index_to_row_mapping[idx] for idx in reviews['business_id']]\n",
    "    # Use the mapped rows to index into the TF-IDF matrix and take the mean\n",
    "    return tfidf_matrix[rows_to_use].mean(axis=0)\n",
    "\n",
    "# Step 3: Profile Creation\n",
    "# Create a user profile based on the reviews they have written\n",
    "# Here, we'll simply average the TF-IDF vectors of the reviews written by the user\n",
    "# Apply the function to each user's reviews\n",
    "user_profiles = review_restaurant_sampled.groupby('user_id').apply(average_tfidf_vectors)\n",
    "\n",
    "# Convert each sparse matrix in the series to a 1-D numpy array\n",
    "user_profiles = user_profiles.apply(lambda x: np.asarray(x).flatten())\n",
    "\n",
    "\n",
    "# Now, since each element in user_profiles is a 1-D array, we can stack them into a 2-D structure\n",
    "# We can use numpy's vstack method to stack the 1-D arrays vertically into a 2-D array\n",
    "import numpy as np\n",
    "user_profiles_np = np.vstack(user_profiles.values)\n",
    "\n",
    "# Now create a DataFrame from this 2-D numpy array\n",
    "user_profiles_df = pd.DataFrame(user_profiles_np, index=user_profiles.index)\n",
    "\n",
    "# Step 4: Similarity Calculation\n",
    "# Calculate cosine similarity between user profiles and business TF-IDF feature vectors\n",
    "cosine_similarities = cosine_similarity(user_profiles_df, tfidf_matrix)\n",
    "\n",
    "# Step 5: Recommendation Generation\n",
    "# Create a DataFrame from the cosine similarities\n",
    "similarity_df = pd.DataFrame(cosine_similarities, index=user_profiles_df.index, columns=business_reviews['business_id'])\n",
    "\n",
    "# Function to get top N recommendations for a user\n",
    "def get_recommendations(user_id, similarity_df, N=10):\n",
    "    # Get the similarity scores for the user\n",
    "    user_similarities = similarity_df.loc[user_id]\n",
    "\n",
    "    # Sort the businesses by similarity score\n",
    "    recommended_business_ids = user_similarities.sort_values(ascending=False).head(N).index\n",
    "\n",
    "    # Get the business details\n",
    "    recommendations = business_restaurant[business_restaurant['business_id'].isin(recommended_business_ids)]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3a2e1",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1700785750351,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "f8b3a2e1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the review data into training and testing sets\n",
    "# train_reviews, test_reviews = train_test_split(review_restaurant_sampled, test_size=0.2)\n",
    "test_reviews = test_df\n",
    "\n",
    "\n",
    "# Function to calculate precision and recall\n",
    "def calculate_precision_recall(user_id, recommendations, test_data):\n",
    "    # True positives: Recommended items that are relevant\n",
    "    tp = len(recommendations[recommendations['business_id'].isin(test_data[test_data['user_id'] == user_id]['business_id'])])\n",
    "    # False positives: Recommended items that are not relevant\n",
    "    fp = len(recommendations) - tp\n",
    "    # False negatives: Relevant items that are not recommended\n",
    "    fn = len(test_data[test_data['user_id'] == user_id]) - tp\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    return precision, recall\n",
    "\n",
    "# Evaluate the model\n",
    "cb_precisions = []\n",
    "cb_recalls = []\n",
    "cb_TopK = 10\n",
    "svd_precisions = []\n",
    "svd_recalls = []\n",
    "ncf_precisions = []\n",
    "ncf_recalls = []\n",
    "cf_TopK = 5\n",
    "\n",
    "count = 0\n",
    "\n",
    "for user_id in test_reviews['user_id'].unique():\n",
    "\n",
    "    # get prediction from content-based system\n",
    "    user_test_data = test_reviews[test_reviews['user_id'] == user_id]\n",
    "    recommendations = get_recommendations(user_id, similarity_df, N=cb_TopK)\n",
    "    cb_recommended_restaruants = recommendations['business_id'].values\n",
    "\n",
    "    # get prediction from content-based collaborative filtering hybrid system\n",
    "    svd_estimate_stars = []\n",
    "    for restaurant_id in cb_recommended_restaruants:\n",
    "        svd_estimate_stars.append(svd_model.predict(uid=user_id, iid=restaurant_id, verbose=False).est)\n",
    "\n",
    "    svd_estimate_stars_numpy = np.array(svd_estimate_stars)\n",
    "    svd_top_k_indices = np.argsort(-svd_estimate_stars_numpy)[:cf_TopK]\n",
    "\n",
    "    svd_recommended_restaurants = [ cb_recommended_restaruants[index] for index in svd_top_k_indices ]\n",
    "    svd_recommendations = business_restaurant[business_restaurant['business_id'].isin(svd_recommended_restaurants)]\n",
    "\n",
    "    # get prediction from content-based SVD hybrid system\n",
    "    user_id_num = np.argmax(users == user_id)\n",
    "    ncf_estimate_stars = []\n",
    "    for restaurant_id in cb_recommended_restaruants:\n",
    "        restaurant_id_num = np.argmax(restaurants == restaurant_id)\n",
    "        ncf_estimate_stars.append(ncf_model.predict([np.array([user_id_num]), np.array([restaurant_id_num])], verbose=0)[0][0])\n",
    "\n",
    "    ncf_estimate_stars_numpy = np.array(ncf_estimate_stars)\n",
    "    ncf_top_k_indices = np.argsort(-ncf_estimate_stars_numpy)[:cf_TopK]\n",
    "\n",
    "    ncf_recommended_restaurants = [ cb_recommended_restaruants[index] for index in ncf_top_k_indices ]\n",
    "    ncf_recommendations = business_restaurant[business_restaurant['business_id'].isin(ncf_recommended_restaurants)]\n",
    "\n",
    "\n",
    "    cb_precision, cb_recall = calculate_precision_recall(user_id, recommendations, user_test_data)\n",
    "    cb_precisions.append(cb_precision)\n",
    "    cb_recalls.append(cb_recall)\n",
    "\n",
    "    svd_precision, svd_recall = calculate_precision_recall(user_id, svd_recommendations, user_test_data)\n",
    "    svd_precisions.append(svd_precision)\n",
    "    svd_recalls.append(svd_recall)\n",
    "\n",
    "    ncf_precision, ncf_recall = calculate_precision_recall(user_id, ncf_recommendations, user_test_data)\n",
    "    ncf_precisions.append(ncf_precision)\n",
    "    ncf_recalls.append(ncf_recall)\n",
    "\n",
    "    count += 1\n",
    "    #print('User:', count)\n",
    "\n",
    "# Calculate the average precision and recall\n",
    "cb_average_precision = sum(cb_precisions) / len(cb_precisions)\n",
    "cb_average_recall = sum(cb_recalls) / len(cb_recalls)\n",
    "cb_f1_score = 2 * (cb_average_precision * cb_average_recall) / (cb_average_precision + cb_average_recall) if (cb_average_precision + cb_average_recall) != 0 else 0\n",
    "\n",
    "svd_average_precision = sum(svd_precisions) / len(svd_precisions)\n",
    "svd_average_recall = sum(svd_recalls) / len(svd_recalls)\n",
    "svd_f1_score = 2 * (svd_average_precision * svd_average_recall) / (svd_average_precision + svd_average_recall) if (svd_average_precision + svd_average_recall) != 0 else 0\n",
    "\n",
    "ncf_average_precision = sum(ncf_precisions) / len(ncf_precisions)\n",
    "ncf_average_recall = sum(ncf_recalls) / len(ncf_recalls)\n",
    "ncf_f1_score = 2 * (ncf_average_precision * ncf_average_recall) / (ncf_average_precision + ncf_average_recall) if (ncf_average_precision + ncf_average_recall) != 0 else 0\n",
    "\n",
    "print(f\"Content-based recommender system prediction Average Precision: {cb_average_precision}\")\n",
    "print(f\"Content-based recommender system prediction Average Recall: {cb_average_recall}\")\n",
    "print(f\"Content-based recommender system prediction F1-Score: {cb_f1_score}\")\n",
    "print()\n",
    "print(f\"Content-based & SVD hybrid recommender system prediction Average Precision: {svd_average_precision}\")\n",
    "print(f\"Content-based & SVD hybrid recommender system prediction Average Recall: {svd_average_recall}\")\n",
    "print(f\"Content-based & SVD hybrid recommender system prediction F1-Score: {svd_f1_score}\")\n",
    "print()\n",
    "print(f\"Content-based & NCF hybrid recommender system prediction Average Precision: {ncf_average_precision}\")\n",
    "print(f\"Content-based & NCF hybrid recommender system prediction Average Recall: {ncf_average_recall}\")\n",
    "print(f\"Content-based & NCF hybrid recommender system prediction F1-Score: {ncf_f1_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01520a",
   "metadata": {
    "id": "5e01520a"
   },
   "source": [
    "### Conclusion about the hybrid system\n",
    "- Content-based & SVD system\n",
    "    - has a higher average precision than simple content-based system\n",
    "    - has a much lower average recall than simple content-based system\n",
    "    - slightly improved the F1-score of simple content-based system\n",
    "- Content-based & NCF system\n",
    "    - has a higher average precision than simple content-based system\n",
    "    - has a much lower average recall than simple content-based system\n",
    "    - has almost the same F1-score as simple content-based system\n",
    "\n",
    "*So finally we will chosse content-based & SVD hybrid system, because it has the best result and SVD is running much faster than NCF model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c7ca3",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1700785750351,
     "user": {
      "displayName": "Toran Shahi",
      "userId": "01554569590000945712"
     },
     "user_tz": -660
    },
    "id": "450c7ca3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
